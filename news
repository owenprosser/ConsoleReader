#!/usr/bin/env python3
import sys, tempfile, os, requests, json, re, asyncio, aiohttp, signal
import urllib.request
from subprocess import call
from pick import pick
from bs4 import BeautifulSoup
from pynput.keyboard import Key, Listener

class HackerNewsReader():
    def __init__(self):
        self.newsItems = []
        self.newsIDs = []
        self.noOfItems = 10
        self.browsedPosition = -1

    def PopulateArticlesList(self):
        r = requests.get('https://hacker-news.firebaseio.com//v0/topstories.json')
        self.newsIDs = json.loads(r.text)

    def PopulateNewsItems(self, startIndex):
        IDlist = self.newsIDs[startIndex:startIndex+self.noOfItems]
        self.newsItems = []
        urls = []
        for id in IDlist:
            requestString = 'https://hacker-news.firebaseio.com/v0/item/'+str(id)+'.json'
            urls.append(requestString)
        client = HttpClient()
        data = asyncio.run(client.main(urls))

        for item in data:
            tempDict = dict()
            tempDict.update({"id":item["id"], "title":item["title"], "url":item["url"]})
            self.newsItems.append(tempDict)

        tempDict.update({"id":000, "title":"\tMore:", "url":"http://example.com"})
        self.browsedPosition = startIndex

    def Menu(self):
        selected = None
        position = 0

        while True:
            if(position != self.browsedPosition):
                self.PopulateNewsItems(position)

            titleList = []
            for i in self.newsItems:
                titleList.append(i["title"])

            selected = pick(titleList, "Menu:", indicator='>')
            selectedUrl = self.newsItems[selected[1]]['url']

            if(None not in selected):
                self.OpenTextInEditor(self.GetHtmlContent(selectedUrl))
            else:
                position += self.noOfItems

    def GetHtmlContent(self, url):
        text = ""
        uf = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        html = uf.content
        soup = BeautifulSoup(html, "lxml")

        for hit in soup.findAll(['h1', 'p']):
            hit = hit.text.strip()
            text += "\n\n" + hit

        return text

    def OpenTextInEditor(self, text):
        EDITOR = os.environ.get('EDITOR','vim')
        message = text.encode()
        with tempfile.NamedTemporaryFile(suffix=".tmp") as tf:
            tf.write(message)
            tf.flush()
            call([EDITOR, tf.name])

            # do the parsing with `tf` using regular File operations.
            # for instance:
            tf.seek(0)

class HttpClient():
    def __init__(self):
        self.url = "https://hacker-news.firebaseio.com/v0/item/"
        self.end = ".json"
        self.data = []

    async def get(self, url, session):
        try:
            async with session.get(url=url) as response:
                resp = await response.read()
                self.data.append(json.loads(resp))
        except Exception as e:
            print("Unable to get url {} due to {}.".format(url, e.__class__))


    async def main(self, urls):
        async with aiohttp.ClientSession() as session:
            ret = await asyncio.gather(*[self.get(url, session) for url in urls])
        return self.data

def signal_handler(sig, frame):
    sys.exit(0)

def on_release(key):
    if key == Key.O:
        print("O Pressed")

if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)

    reader = HackerNewsReader()
    reader.PopulateArticlesList()

    reader.Menu()